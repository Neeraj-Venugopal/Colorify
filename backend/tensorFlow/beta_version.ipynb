{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "X = []\n",
    "for filename in os.listdir('../Full-version/Train/'):\n",
    "    X.append(img_to_array(load_img('../Full-version/Train/'+filename)))\n",
    "X = np.array(X, dtype=float)\n",
    "\n",
    "# Set up train and test data\n",
    "split = int(0.95*len(X))\n",
    "Xtrain = X[:split]\n",
    "Xtrain = 1.0/255*Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.9922\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0164\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0164\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0177\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0647\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0176\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0169\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0195\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0175\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0173\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0174\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0168\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0171\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0168\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0173\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0177\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0169\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 35s 4s/step - loss: 1.0164\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0177\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0168\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0178\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0156\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0168\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0168\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0179\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0174\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0178\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0163\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0182\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0169\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0160\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0172\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0168\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0181\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0164\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0168\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0167\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0169\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0174\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0176\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0173\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0168\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0173\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0167\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0173\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0158\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0170\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 1.0166\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 1.0168\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0159\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 1.0168\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0164\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0165\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0169\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0157\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0166\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0175\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0166\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0155\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0168\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.0168\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 31s 3s/step - loss: 1.0175\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0167\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0169\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.0172\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0163\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0165\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0161\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0170\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0158\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0161\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0162\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0166\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0174\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0161\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0160\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0170\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0164\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.0170\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0157\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 1.0169\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 1.0162\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0165\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 31s 3s/step - loss: 1.0163\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.0156\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0160\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0177\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0161\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0173\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0163\n",
      "Epoch 91/100\n"
     ]
    }
   ],
   "source": [
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 10\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "# Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"output/first_run\")\n",
    "model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=100, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 707ms/step\n",
      "1.0049654245376587\n"
     ]
    }
   ],
   "source": [
    "# Test images\n",
    "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "Ytest = Ytest / 128\n",
    "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 34189 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 62965 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 63655 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 52890 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 51587 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 29747 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 34301 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 23990 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/home/neeraj/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 56107 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "color_me = []\n",
    "for filename in os.listdir('../Full-version/Test/'):\n",
    "    color_me.append(img_to_array(load_img('../Full-version/Test/'+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "# Test model\n",
    "output = model.predict(color_me)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
